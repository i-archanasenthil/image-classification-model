{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIZOrZMuI3AP"
      },
      "source": [
        "### Assignment 3\n",
        "\n",
        "#### Flower classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsYgq3fPI3AT"
      },
      "source": [
        "Adapt the method of Lecture 9 from binary classification to $C$-class classification ($C=5$) to classify images of flowers in [my repository](https://github.com/mgreenbe/flower-classification.git).\n",
        "\n",
        "- Use an random 80%/20% split of the data into training and validation.\n",
        "\n",
        "- Use a ResNet18, ResNet34, or a ResNet50 model, pretrained on ImageNet, with the classification head replaced as appropriate to our problem.\n",
        "\n",
        "- At the end of each training epoch compute and print out the [cross-entropy loss](https://pytorch.org/docs/stable/generated/torch.nn.functional.cross_entropy.html) and classification accuracy on the validation set.\n",
        "\n",
        "- Time permitting, look into some tricks you might use to improve your classifier, e.g. [randomly flipping training images horizontally](https://pytorch.org/vision/0.20/generated/torchvision.transforms.RandomHorizontalFlip.html). (Why might this help?)\n",
        "\n",
        "- You're also welcome to experiment with other vision models beyond the ResNets. If you find one that works particularly well, let me know!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "e-QQ8c1vJwuc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Linear\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torch.optim import Adam\n",
        "from torchvision.transforms import Compose, Normalize, Resize, ToTensor\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.models import resnet18, resnet34\n",
        "from pathlib import Path\n",
        "from matplotlib import pyplot as plt\n",
        "import random\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "F4D-8YktJ82U"
      },
      "outputs": [],
      "source": [
        "transformations = Compose([\n",
        "    Resize((128,128)),\n",
        "    ToTensor(),\n",
        "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "Dptm5iMEKjFu",
        "outputId": "471e00eb-4cca-48fd-c501-0266c5d46b81"
      },
      "outputs": [],
      "source": [
        "ds = ImageFolder('assets', transform=transformations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "daisy: 769 images (17.79%)\n",
            "dandelion: 1052 images (24.33%)\n",
            "rose: 784 images (18.14%)\n",
            "sunflower: 734 images (16.98%)\n",
            "tulip: 984 images (22.76%)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Get class names and their corresponding indices\n",
        "class_to_idx = ds.class_to_idx  \n",
        "\n",
        "class_counts = Counter(label for _, label in ds)\n",
        "\n",
        "total_images = len(ds)\n",
        "\n",
        "for class_name, class_idx in class_to_idx.items():\n",
        "    count = class_counts[class_idx]\n",
        "    share = (count / total_images) * 100  \n",
        "    print(f\"{class_name}: {count} images ({share:.2f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfTFiAN-ioIk"
      },
      "source": [
        "Use an random 80%/20% split of the data into training and validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "VvVYSvHxhDFF",
        "outputId": "fde48f09-e2eb-4a49-968b-e6be03cd6e92"
      },
      "outputs": [],
      "source": [
        "\n",
        "train_size = int(0.8 * len(ds))\n",
        "val_size = len(ds) - train_size  # Ensures total matches dataset size\n",
        "\n",
        "train_ds, val_ds = random_split(ds, [train_size, val_size])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "QwI_HaE_hMam"
      },
      "outputs": [],
      "source": [
        "train_dl = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
        "val_dl = DataLoader(val_ds, batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "L8i1Q62nkEnN"
      },
      "outputs": [],
      "source": [
        "def accuracy(yy, y):\n",
        "  return torch.mean(1.0*(yy.argmax(dim=1) == y)).item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: certifi in c:\\python\\python39\\lib\\site-packages (2025.1.31)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Error parsing dependencies of ipykernel: Expected matching RIGHT_PARENTHESIS for LEFT_PARENTHESIS, after version specifier\n",
            "    matplotlib-inline (<0.2.0appnope,>=0.1.0) ; platform_system == \"Darwin\"\n",
            "                      ~~~~~~~~^\n"
          ]
        }
      ],
      "source": [
        "# to resolve outdated certificate error\n",
        "!pip install --upgrade certifi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50J2HpnHisCA"
      },
      "source": [
        "Use a ResNet18, ResNet34, or a ResNet50 model, pretrained on ImageNet, with the classification head replaced as appropriate to our problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "k4ix1b1Oist6"
      },
      "outputs": [],
      "source": [
        "model18 = resnet18(weights=\"IMAGENET1K_V1\")\n",
        "model18.fc = Linear(model18.fc.in_features, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0, 1, 2, 3, 4])\n"
          ]
        }
      ],
      "source": [
        "print(y.unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "O-7vQGFokGBp"
      },
      "outputs": [],
      "source": [
        "opt = torch.optim.Adam(model18.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "zcvMDkUCkNU-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing batch 0 of 55.\n",
            "loss = 1.803179144859314.\n",
            "Processing batch 50 of 55.\n",
            "loss = 0.5027329325675964.\n"
          ]
        }
      ],
      "source": [
        "#model18.to(\"cuda\")\n",
        "\n",
        "loss_train = []\n",
        "acc_train = []\n",
        "for epoch in range(1):\n",
        "  model18.train()\n",
        "  for i, (X, y) in enumerate(train_dl):\n",
        "    if i % 50 == 0:\n",
        "      print(f\"Processing batch {i} of {len(train_dl)}.\")\n",
        "    #X = X.to(\"cuda\")\n",
        "    #y = y.double().to(\"cuda\")\n",
        "    y = y.long()\n",
        "    logits = model18(X)\n",
        "    loss = F.cross_entropy(logits, y)\n",
        "    opt.zero_grad()\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    \n",
        "    loss_train.append(loss.detach().item())\n",
        "    if i % 50 == 0:\n",
        "      print(f\"loss = {loss.detach().item()}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hy0FUfAfkWZf"
      },
      "source": [
        "ResNet34"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "lvBbl_uJka-V"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to C:\\Users\\Achu/.cache\\torch\\hub\\checkpoints\\resnet34-b627a593.pth\n",
            "100.0%\n"
          ]
        }
      ],
      "source": [
        "model34 = resnet34(weights=\"IMAGENET1K_V1\")\n",
        "model34.fc = Linear(model34.fc.in_features, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "p8lQ4l3ykjyS"
      },
      "outputs": [],
      "source": [
        "opt = torch.optim.Adam(model34.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "elzO1Oj0kmcs"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing batch 0 of 55.\n",
            "loss = 2.2447547912597656.\n",
            "Processing batch 50 of 55.\n",
            "loss = 0.7109651565551758.\n"
          ]
        }
      ],
      "source": [
        "#model34.to(\"cuda\")\n",
        "\n",
        "loss_train = []\n",
        "acc_train = []\n",
        "for epoch in range(1):\n",
        "  model34.train()\n",
        "  for i, (X, y) in enumerate(train_dl):\n",
        "    if i % 50 == 0:\n",
        "      print(f\"Processing batch {i} of {len(train_dl)}.\")\n",
        "    X = X\n",
        "    y = y.long()\n",
        "    logits = model34(X)\n",
        "    loss = F.cross_entropy(logits, y)\n",
        "\n",
        "    opt.zero_grad()\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    \n",
        "    loss_train.append(loss.detach().item())\n",
        "    if i % 50 == 0:\n",
        "      print(f\"loss = {loss.detach().item()}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C89amgXTmVOG"
      },
      "source": [
        "At the end of each training epoch compute and print out the cross-entropy loss and classification accuracy on the validation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "hbNeyrA6mUYw"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, val_dl):\n",
        "    loss_val = []\n",
        "    acc_val = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for i, (X,y) in enumerate(val_dl):\n",
        "            X= X\n",
        "            y = y.long()\n",
        "            logits = model(X)\n",
        "            loss = F.cross_entropy(logits, y)\n",
        "            loss_val.append(loss.item())\n",
        "            _, predicted = torch.max(logits, dim=1)\n",
        "            acc = torch.mean((predicted == y).double())\n",
        "            acc_val.append(acc)\n",
        "    return loss_val, acc_val\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss_val, acc_val = evaluate(model18,val_dl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(0.7461)"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.mean(torch.Tensor(acc_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss_val, acc_val = evaluate(model34,val_dl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(0.7138)"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.mean(torch.Tensor(acc_val))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Randomly flipping trainingimages horizontally can improve the performance of the classifier because\n",
        "\n",
        "1) Creaes new variation of the existing training image, thereby increasing diversity \n",
        "2) Avoid overfitting a specific orientation of the images \n",
        "3) The decision boundaries learned by the classifier becomes smoother, meaning model can classify instances with more flexibility and robustness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
